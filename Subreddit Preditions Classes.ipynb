{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Gathering the Data\n",
    "The first step is to gather a large amount of data and to store it in a pandas dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import secrets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.svm import SVC\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "user_agent = \"Subreddit-Predictor 0.1 by /u/IsThisATrollBot\"\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=secrets.client_ID,\n",
    "    client_secret=secrets.client_secret,\n",
    "    password=secrets.password,\n",
    "    user_agent=user_agent,\n",
    "    username=secrets.username,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because pushshift is down, we are limited to the amount of data we can gather at a time. So we will choose posts from the 10 most popular subreddits."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Start with a list of subreddits\n",
    "top_subreddits = ['announcements', 'funny', 'AskReddit', 'gaming', 'Awww', 'Music', 'pics', 'science', 'worldnews', 'videos', 'AmItheAsshole']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Create an empty list to store the posts\n",
    "posts = []\n",
    "\n",
    "# Iterate through the subreddits and get the last 1000 posts from each\n",
    "for sub in top_subreddits:\n",
    "    subreddit_posts = reddit.subreddit(sub).new(limit=1000)\n",
    "    for post in subreddit_posts:\n",
    "        posts.append(post)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# Create a list of dictionaries containing the data for each post\n",
    "data = [{'id': post.id, 'title': post.title, 'subreddit': post.subreddit.display_name} for post in posts]\n",
    "\n",
    "# Create a Pandas dataframe from the list of dictionaries\n",
    "df = pd.DataFrame(data)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [],
   "source": [
    "test_titles = ['Redditors of Reddit. What is your favorite piece of Reddit history?', 'WIBTA if I stole my younger brothers lunch money?', 'check out this cool video I found', 'asdf', 'cats are dangerous', 'new study shows cats are dangerous', 'reddit cool aita']\n",
    "test_titles = pd.DataFrame({'title':test_titles})\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main Subreddit Predictor Class\n",
    "\n",
    "This will have as attributes the Feature Vectorizers and the Classifiers, which themselves are objects of other classes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "outputs": [],
   "source": [
    "class Subreddit_Predictor:\n",
    "    def __init__(self):\n",
    "        self.raw_data = pd.DataFrame({'id':[], 'title':[], 'subreddit':[]})\n",
    "        self.subreddits = []\n",
    "        self.data = pd.DataFrame({'id':[], 'title':[], 'subreddit':[]})\n",
    "        self.Feature_Vectors = {}\n",
    "        self.Embedding = {}\n",
    "        self.Title_Vectorizers = {}\n",
    "        self.Classifiers = {}\n",
    "        self.Models = {}\n",
    "        self.Models_info = {}\n",
    "\n",
    "    def add_data(self, df):\n",
    "        \"\"\"df is a pandas DataFrame with columns={'title':[], 'subreddit':[]}. It will be merged with the existing raw_data\"\"\"\n",
    "        self.raw_data = pd.concat([self.raw_data, df]).drop_duplicates(subset='id')\n",
    "\n",
    "    def clean_data(self):\n",
    "        \"\"\"Cleans the data in raw_data and updates self.data\"\"\"\n",
    "\n",
    "        df = self.raw_data\n",
    "\n",
    "        # Remove all non-alpha-numeric characters\n",
    "        df['title'] = df['title'].str.replace(r'[^a-zA-Z0-9 ]', '', regex = True)\n",
    "\n",
    "        # Make all the text lowercase\n",
    "        df['title'] = df['title'].str.lower()\n",
    "\n",
    "        # Remove empty rows\n",
    "        df['title'] = df['title'].str.strip()\n",
    "        filter = df['title'] == ''\n",
    "        df = df.drop(df[filter].index)\n",
    "\n",
    "        # Store it as\n",
    "        self.data = df\n",
    "\n",
    "        #update the subreddits attribute\n",
    "        self.subreddits = self.data['subreddit'].unique().tolist()\n",
    "\n",
    "    def ready_data(self, test_size = .2, seed = 42):\n",
    "        \"\"\"Splits and encodes the data. Saves is in X_train, Y_train, X_test, Y_test.\"\"\"\n",
    "\n",
    "        # Change the index\n",
    "        self.data = self.data.set_index('id')\n",
    "\n",
    "        # Encode the subreddits\n",
    "        self._le = LabelEncoder()\n",
    "        self.data['subreddit_num'] = self._le.fit_transform(self.data['subreddit'])\n",
    "\n",
    "        # Split the data\n",
    "        self.X_train, self.X_test, self.Y_train, self.Y_test = train_test_split(self.data['title'], self._le.fit_transform(self.data['subreddit']), test_size=test_size, random_state = seed)\n",
    "\n",
    "    def add_title_vectorizer(self, title_vectorizer):\n",
    "        \"\"\"This is how we add a title_vectorizer to our collection\"\"\"\n",
    "        title_vectorizer.train(self.X_train)\n",
    "        self.Title_Vectorizers[title_vectorizer.featureName] = title_vectorizer\n",
    "        self.Feature_Vectors[title_vectorizer.featureName] = title_vectorizer.vectorize(self.X_train)\n",
    "\n",
    "    def add_classifier(self, classifier):\n",
    "        \"\"\"We add the classifier to our collection, self.Classifiers\"\"\"\n",
    "        self.Classifiers[classifier.classifierName] = classifier\n",
    "\n",
    "    def train_model(self, modelName, featureName, classifierName, description = ''):\n",
    "        \"\"\"\n",
    "        :param modelName: The name of this model\n",
    "        :param featureName: Which feature vectors are we using?\n",
    "        :param classifierName: Which classifier are we using?\n",
    "        :param description: Write a short discription of the model (optional).\n",
    "        :return: Adds a trained object of the classifier class to self.Models\n",
    "        \"\"\"\n",
    "\n",
    "        self.Models_info[modelName] = {'featureName':featureName, 'classifierName':classifierName, 'description':description}\n",
    "\n",
    "        X_train = self.Feature_Vectors[featureName]\n",
    "        Y_train = self.Y_train\n",
    "        classifier = self.Classifiers[classifierName]\n",
    "        classifier.train(X_train, Y_train)\n",
    "\n",
    "        self.Models[modelName] = classifier\n",
    "\n",
    "\n",
    "    def predictions(self, modelName, titles):\n",
    "        \"\"\"\n",
    "        :param modelName: Which model are we using?\n",
    "        :param titles: A list or series of titles\n",
    "        :return: A data frame of 'title' and 'prediction'\n",
    "        \"\"\"\n",
    "\n",
    "        model = self.Models[modelName]\n",
    "\n",
    "        featureName = self.Models_info[modelName]['featureName']\n",
    "        vectorizer = self.Title_Vectorizers[featureName]\n",
    "\n",
    "        title_vectors = vectorizer.vectorize(titles)\n",
    "\n",
    "        df = model.predict(title_vectors)\n",
    "        #df['prediction'] = self._le.inverse_transform(df['prediction'])\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def generate_features(self, featureName):\n",
    "        \"\"\"Generates the features using the different methods we have created\"\"\"\n",
    "\n",
    "        if featureName == 'BoW':\n",
    "            self.Embedding['BoW'] = CountVectorizer()\n",
    "            self.Features['BoW'] = self.Embedding['BoW'].fit_transform(self.X_train)\n",
    "\n",
    "        if featureName == 'D2V':\n",
    "\n",
    "            # Create a list of TaggedDocument objects from the titles\n",
    "            X_train_tagged = self.X_train.tolist()\n",
    "            X_train_tagged = [TaggedDocument(words=title.split(), tags=[str(i)]) for i, title in enumerate(X_train_tagged)]\n",
    "            X_test_tagged = self.X_test.tolist()\n",
    "            X_test_tagged = [TaggedDocument(words=title.split(), tags=[str(i)]) for i, title in enumerate(X_test_tagged)]\n",
    "\n",
    "            model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "            model_dbow.build_vocab(X_train_tagged)\n",
    "\n",
    "            # Train the model\n",
    "            model_dbow.train(X_train_tagged, total_examples=model_dbow.corpus_count, epochs=100)\n",
    "\n",
    "            # Get the vectorized titles from the doc2vec model\n",
    "            vectors = [model_dbow.infer_vector(title.split()) for title in X_train.tolist()]\n",
    "\n",
    "            # Add the vectors to the dataframe as a new column\n",
    "            df_new = pd.DataFrame({'title':X_train, 'vector': vectors})\n",
    "            df_new\n",
    "\n",
    "    def vectorize(self, featureName, x):\n",
    "        \"\"\"Turns a sentence or list of sentences into a feature vectors\"\"\"\n",
    "\n",
    "        if type(x) == str: return self.vectorize(featureName, [x])\n",
    "\n",
    "        else:\n",
    "            if featureName == 'BoW':\n",
    "                return self.Embedding['BoW'].transform(x).toarray()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "outputs": [],
   "source": [
    "obj = Subreddit_Predictor()\n",
    "obj.add_data(df)\n",
    "obj.clean_data()\n",
    "obj.ready_data(test_size=.3, seed=29)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "outputs": [
    {
     "data": {
      "text/plain": "{}"
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.Models_info"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BoW+SVM'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_31196\\1508582895.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'BoW+SVM'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_titles\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_31196\\3387029083.py\u001B[0m in \u001B[0;36mpredictions\u001B[1;34m(self, modelName, titles)\u001B[0m\n\u001B[0;32m     86\u001B[0m         \"\"\"\n\u001B[0;32m     87\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 88\u001B[1;33m         \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mModels\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmodelName\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     89\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m         \u001B[0mfeatureName\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mModels_info\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmodelName\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'featureName'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'BoW+SVM'"
     ]
    }
   ],
   "source": [
    "obj.predictions('BoW+SVM', test_titles)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Title Vectorizer Class\n",
    "\n",
    "This will have all of the different vectorizers. All of the different ways to embed titles.\n",
    "A key feature of this class is that there are functions which need to be added later."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "outputs": [],
   "source": [
    "class Title_Vectorizer:\n",
    "    \"\"\"This class is to hold all of the Title Vectorizers, like Bag-of-Words and Doc2Vec. Each vectorizer is a specific object. The class methods all have the same input/output.\"\"\"\n",
    "    def __init__(self, featureName):\n",
    "        self.featureName = featureName\n",
    "        self.description = \"Description goes here\"\n",
    "\n",
    "    def train(self, X_train):\n",
    "        \"\"\"Inputs the training data. Creates the self.model\"\"\"\n",
    "\n",
    "        self.model = self._train(X_train)\n",
    "\n",
    "    def _train(self, X_train):\n",
    "        \"\"\"Just a place holder for the actual function\"\"\"\n",
    "        #pass\n",
    "\n",
    "    def vectorize(self, df_titles):\n",
    "        \"\"\"Given a data frame or series with only titles, will return a df of all of the features, indexed by id. The actual function will be added to each object.\"\"\"\n",
    "\n",
    "        return self._vectorize(df_titles, self.model)\n",
    "\n",
    "    def _vectorize(self, df_titles, model):\n",
    "        \"\"\"Just a place holder for the actual function.\"\"\"\n",
    "        #pass\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example: Bag-of-Words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "outputs": [],
   "source": [
    "BoW_model = Title_Vectorizer('BoW')\n",
    "\n",
    "def _BoW_vectorize(df_titles, model):\n",
    "    \"\"\"I think I need to drop every word that's not in the vocabulary.\"\"\"\n",
    "\n",
    "    if type(df_titles) == pd.core.frame.DataFrame:\n",
    "        titles = df_titles['title']\n",
    "    else:\n",
    "        titles = df_titles\n",
    "\n",
    "    vocab = model.vocabulary_\n",
    "\n",
    "    titles = titles.apply(lambda s: ' '.join(set(s.split()).intersection(vocab)))\n",
    "    temp = model.transform(titles)\n",
    "    temp = temp.toarray()\n",
    "    temp = pd.DataFrame(temp)\n",
    "    temp['id'] =df_titles.index\n",
    "    temp = temp.set_index('id')\n",
    "    return temp\n",
    "\n",
    "def _BoW_train(X_train):\n",
    "    model = CountVectorizer()\n",
    "    model.fit_transform(X_train)\n",
    "    return model\n",
    "\n",
    "BoW_model._vectorize = _BoW_vectorize\n",
    "BoW_model._train = _BoW_train\n",
    "\n",
    "obj.add_title_vectorizer(BoW_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "outputs": [
    {
     "data": {
      "text/plain": "    0      1      2      3      4      5      6      7      8      9      ...  \\\nid                                                                        ...   \n0       0      0      0      0      0      0      0      0      0      0  ...   \n1       0      0      0      0      0      0      0      0      0      0  ...   \n2       0      0      0      0      0      0      0      0      0      0  ...   \n3       0      0      0      0      0      0      0      0      0      0  ...   \n4       0      0      0      0      0      0      0      0      0      0  ...   \n5       0      0      0      0      0      0      0      0      0      0  ...   \n6       0      0      0      0      0      0      0      0      0      0  ...   \n\n    13126  13127  13128  13129  13130  13131  13132  13133  13134  13135  \nid                                                                        \n0       0      0      0      0      0      0      0      0      0      0  \n1       0      0      0      0      0      0      0      0      0      0  \n2       0      0      0      0      0      0      0      0      0      0  \n3       0      0      0      0      0      0      0      0      0      0  \n4       0      0      0      0      0      0      0      0      0      0  \n5       0      0      0      0      0      0      0      0      0      0  \n6       0      0      0      0      0      0      0      0      0      0  \n\n[7 rows x 13136 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>13126</th>\n      <th>13127</th>\n      <th>13128</th>\n      <th>13129</th>\n      <th>13130</th>\n      <th>13131</th>\n      <th>13132</th>\n      <th>13133</th>\n      <th>13134</th>\n      <th>13135</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7 rows × 13136 columns</p>\n</div>"
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BoW_model.vectorize(test_titles)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example: Doc2Vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "outputs": [],
   "source": [
    "D2V_model = Title_Vectorizer('D2V')\n",
    "#D2V_model.params = {'dm':0, 'vector_size':300, 'negative':5, 'hs':0, 'min_count':2, 'sample':0, 'epochs':100}\n",
    "\n",
    "def _D2V_train(X_train):\n",
    "\n",
    "    X_train_tagged = X_train.tolist()\n",
    "    X_train_tagged = [TaggedDocument(words=title.split(), tags=[str(i)]) for i, title in enumerate(X_train_tagged)]\n",
    "\n",
    "    model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0)\n",
    "    model_dbow.build_vocab(X_train_tagged)\n",
    "\n",
    "    # Train the model\n",
    "    model_dbow.train(X_train_tagged, total_examples=model_dbow.corpus_count, epochs=100)\n",
    "\n",
    "    return model_dbow\n",
    "\n",
    "def _D2V_vectorize(df_titles, model):\n",
    "\n",
    "    vectors = [model.infer_vector(titl.split()) for titl in df_titles.tolist()]\n",
    "    df_new = pd.DataFrame({'title':df_titles, 'vector': vectors})\n",
    "    df_new =df_new['vector'].apply(lambda x: pd.Series(x))\n",
    "\n",
    "    return df_new\n",
    "\n",
    "D2V_model._train = _D2V_train\n",
    "D2V_model._vectorize = _D2V_vectorize\n",
    "\n",
    "obj.add_title_vectorizer(D2V_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classifiers\n",
    "\n",
    "This is the class that holds the classifiers, like XGBoost and Support Vector Machines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "outputs": [],
   "source": [
    "class classifier:\n",
    "    \"\"\"This is the class the holds the classifiers\"\"\"\n",
    "\n",
    "    def __init__(self, classifierName):\n",
    "        self.classifierName = classifierName\n",
    "\n",
    "    def train(self, X_train, Y_train):\n",
    "        \"\"\"Input the X and Y training data. Then update the model\"\"\"\n",
    "\n",
    "        self.model = self._train(X_train, Y_train)\n",
    "\n",
    "    def _train(self, X_train, Y_train):\n",
    "        \"\"\"Where the real function is stored\"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict(self, title_vectors):\n",
    "        \"\"\"\n",
    "        :param title_vectors: A pandas dataframe of the vectorized titles\n",
    "        :return: A pandas series with the predictions\n",
    "        \"\"\"\n",
    "\n",
    "        return self._predict(title_vectors, self.model)\n",
    "\n",
    "    def _predict(self, titles, model):\n",
    "        \"\"\"where the actual function is stored\"\"\"\n",
    "        pass\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example: Support Vector Machine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "outputs": [],
   "source": [
    "SVM_model = classifier('SVM')\n",
    "\n",
    "def _SVM_train(X_train, Y_train):\n",
    "    model = SVC()\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model\n",
    "\n",
    "def _SVM_predict(title_vectors, model):\n",
    "    \"\"\"enter a list or series or data frame of titles. Outputs prediction in a dataframe\"\"\"\n",
    "\n",
    "    df = model.predict(title_vectors)\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "SVM_model._train = _SVM_train\n",
    "SVM_model._predict = _SVM_predict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "outputs": [],
   "source": [
    "obj.add_classifier(SVM_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "outputs": [],
   "source": [
    "obj.train_model('BoW+SVM', 'BoW', 'SVM', description= 'Just a quick test')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  2  1 ...  0  2  5]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([10,  2,  1, ...,  0,  2,  5])"
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.predictions('BoW+SVM', obj.X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               title\n0  Redditors of Reddit. What is your favorite pie...\n1  WIBTA if I stole my younger brothers lunch money?\n2                  check out this cool video I found\n3                                               asdf\n4                                 cats are dangerous\n5                 new study shows cats are dangerous\n6                                   reddit cool aita",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Redditors of Reddit. What is your favorite pie...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WIBTA if I stole my younger brothers lunch money?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>check out this cool video I found</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>asdf</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cats are dangerous</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>new study shows cats are dangerous</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>reddit cool aita</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_titles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Test the model on some new data\n",
    "new_titles = ['Redditors of Reddit. What is your favorite piece of Reddit history?', 'WIBTA if I stole my younger brothers lunch money?', 'check out this cool video I found', 'asdf', 'cats are dangerous', 'new study shows cats are dangerous']\n",
    "new_vectors = Embedding[featureName].transform(new_titles)\n",
    "\n",
    "new_predictions = Models[(featureName, classifierName)].predict(new_vectors)\n",
    "\n",
    "output = pd.DataFrame({'title': new_titles, 'Prediction':new_predictions})\n",
    "output['Prediction'] = le.inverse_transform(output['Prediction'])\n",
    "output\n",
    "\n",
    "\n",
    "\n",
    "Models[(featureName, classifierName)] = SVC()\n",
    "Models[(featureName, classifierName)].fit(Features[featureName], Y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4         5         6    \\\nid                                                                             \nzmng91  0.124582  0.243396 -0.285233 -0.292657 -0.014337  0.445207 -0.584179   \nzrve0c -0.004741 -0.048354 -0.019651  0.165643  0.224330 -0.055640  0.132605   \nzppddb -0.179380 -0.124213 -0.161055 -0.325073  0.329091  0.191743 -0.130025   \nz4m4c6  0.250896  0.154340 -0.385988 -0.629014 -0.081034  0.143091 -0.314824   \nzeb9r7 -0.146872 -0.105383 -0.286352 -0.282161 -0.200312  0.248168  0.129567   \n...          ...       ...       ...       ...       ...       ...       ...   \nzo36za -0.155573 -0.220176 -0.221153 -0.198772  0.298348  0.069892 -0.002548   \nzog02f -0.059888  0.015476 -0.141179 -0.296559  0.308300  0.254743 -0.255748   \nzophno  0.183705 -0.059724 -0.451903 -0.299384  0.058367 -0.039836  0.067061   \nz7sghp -0.144103 -0.134290 -0.347879 -0.160396 -0.153021  0.074020 -0.274817   \nzodvmd -0.077790 -0.151644 -0.057777  0.015539  0.124159 -0.127192 -0.381995   \n\n             7         8         9    ...       290       291       292  \\\nid                                    ...                                 \nzmng91  0.101635  0.353450 -0.048465  ... -0.243792 -0.224315 -0.410018   \nzrve0c  0.051793  0.226556  0.173038  ... -0.269658  0.125007  0.144099   \nzppddb -0.047308  0.119915 -0.075613  ...  0.136019 -0.035714  0.208921   \nz4m4c6  0.227359  0.227642  0.256662  ... -0.277127 -0.193340  0.011218   \nzeb9r7  0.261246  0.109793 -0.123065  ... -0.065415 -0.211845 -0.109918   \n...          ...       ...       ...  ...       ...       ...       ...   \nzo36za  0.319032  0.114219 -0.163150  ... -0.032943 -0.141069  0.084034   \nzog02f -0.029594 -0.051015  0.067890  ... -0.001212 -0.005342 -0.233871   \nzophno  0.238934  0.267701 -0.052739  ...  0.139718  0.125756  0.168113   \nz7sghp -0.007368  0.148038 -0.135822  ... -0.145126  0.029284 -0.306107   \nzodvmd -0.249851  0.151266  0.159449  ... -0.049719  0.040907 -0.141377   \n\n             293       294       295       296       297       298       299  \nid                                                                            \nzmng91 -0.119891  0.138223  0.247556 -0.099369  0.422833 -0.377174 -0.098506  \nzrve0c -0.173289  0.147958  0.399452 -0.271192  0.050419 -0.114187 -0.187126  \nzppddb  0.114411  0.384664  0.022161 -0.138315 -0.147456 -0.063236 -0.258442  \nz4m4c6 -0.225516 -0.167319  0.141716 -0.445301  0.008907  0.006306  0.060325  \nzeb9r7 -0.269352  0.092641 -0.232515 -0.216349 -0.031634 -0.097747  0.265720  \n...          ...       ...       ...       ...       ...       ...       ...  \nzo36za -0.089177  0.038817  0.289343 -0.071765 -0.141827 -0.135069 -0.143151  \nzog02f -0.124089  0.124338  0.284089 -0.244712  0.168567 -0.076076 -0.086543  \nzophno  0.080182  0.112720  0.434177 -0.110954 -0.192290  0.096343  0.133488  \nz7sghp  0.214905 -0.032107  0.199594 -0.493793 -0.173641 -0.092477  0.060075  \nzodvmd  0.091956 -0.027756  0.071189 -0.137783  0.050524 -0.203722 -0.260013  \n\n[6477 rows x 300 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>zmng91</th>\n      <td>0.124582</td>\n      <td>0.243396</td>\n      <td>-0.285233</td>\n      <td>-0.292657</td>\n      <td>-0.014337</td>\n      <td>0.445207</td>\n      <td>-0.584179</td>\n      <td>0.101635</td>\n      <td>0.353450</td>\n      <td>-0.048465</td>\n      <td>...</td>\n      <td>-0.243792</td>\n      <td>-0.224315</td>\n      <td>-0.410018</td>\n      <td>-0.119891</td>\n      <td>0.138223</td>\n      <td>0.247556</td>\n      <td>-0.099369</td>\n      <td>0.422833</td>\n      <td>-0.377174</td>\n      <td>-0.098506</td>\n    </tr>\n    <tr>\n      <th>zrve0c</th>\n      <td>-0.004741</td>\n      <td>-0.048354</td>\n      <td>-0.019651</td>\n      <td>0.165643</td>\n      <td>0.224330</td>\n      <td>-0.055640</td>\n      <td>0.132605</td>\n      <td>0.051793</td>\n      <td>0.226556</td>\n      <td>0.173038</td>\n      <td>...</td>\n      <td>-0.269658</td>\n      <td>0.125007</td>\n      <td>0.144099</td>\n      <td>-0.173289</td>\n      <td>0.147958</td>\n      <td>0.399452</td>\n      <td>-0.271192</td>\n      <td>0.050419</td>\n      <td>-0.114187</td>\n      <td>-0.187126</td>\n    </tr>\n    <tr>\n      <th>zppddb</th>\n      <td>-0.179380</td>\n      <td>-0.124213</td>\n      <td>-0.161055</td>\n      <td>-0.325073</td>\n      <td>0.329091</td>\n      <td>0.191743</td>\n      <td>-0.130025</td>\n      <td>-0.047308</td>\n      <td>0.119915</td>\n      <td>-0.075613</td>\n      <td>...</td>\n      <td>0.136019</td>\n      <td>-0.035714</td>\n      <td>0.208921</td>\n      <td>0.114411</td>\n      <td>0.384664</td>\n      <td>0.022161</td>\n      <td>-0.138315</td>\n      <td>-0.147456</td>\n      <td>-0.063236</td>\n      <td>-0.258442</td>\n    </tr>\n    <tr>\n      <th>z4m4c6</th>\n      <td>0.250896</td>\n      <td>0.154340</td>\n      <td>-0.385988</td>\n      <td>-0.629014</td>\n      <td>-0.081034</td>\n      <td>0.143091</td>\n      <td>-0.314824</td>\n      <td>0.227359</td>\n      <td>0.227642</td>\n      <td>0.256662</td>\n      <td>...</td>\n      <td>-0.277127</td>\n      <td>-0.193340</td>\n      <td>0.011218</td>\n      <td>-0.225516</td>\n      <td>-0.167319</td>\n      <td>0.141716</td>\n      <td>-0.445301</td>\n      <td>0.008907</td>\n      <td>0.006306</td>\n      <td>0.060325</td>\n    </tr>\n    <tr>\n      <th>zeb9r7</th>\n      <td>-0.146872</td>\n      <td>-0.105383</td>\n      <td>-0.286352</td>\n      <td>-0.282161</td>\n      <td>-0.200312</td>\n      <td>0.248168</td>\n      <td>0.129567</td>\n      <td>0.261246</td>\n      <td>0.109793</td>\n      <td>-0.123065</td>\n      <td>...</td>\n      <td>-0.065415</td>\n      <td>-0.211845</td>\n      <td>-0.109918</td>\n      <td>-0.269352</td>\n      <td>0.092641</td>\n      <td>-0.232515</td>\n      <td>-0.216349</td>\n      <td>-0.031634</td>\n      <td>-0.097747</td>\n      <td>0.265720</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>zo36za</th>\n      <td>-0.155573</td>\n      <td>-0.220176</td>\n      <td>-0.221153</td>\n      <td>-0.198772</td>\n      <td>0.298348</td>\n      <td>0.069892</td>\n      <td>-0.002548</td>\n      <td>0.319032</td>\n      <td>0.114219</td>\n      <td>-0.163150</td>\n      <td>...</td>\n      <td>-0.032943</td>\n      <td>-0.141069</td>\n      <td>0.084034</td>\n      <td>-0.089177</td>\n      <td>0.038817</td>\n      <td>0.289343</td>\n      <td>-0.071765</td>\n      <td>-0.141827</td>\n      <td>-0.135069</td>\n      <td>-0.143151</td>\n    </tr>\n    <tr>\n      <th>zog02f</th>\n      <td>-0.059888</td>\n      <td>0.015476</td>\n      <td>-0.141179</td>\n      <td>-0.296559</td>\n      <td>0.308300</td>\n      <td>0.254743</td>\n      <td>-0.255748</td>\n      <td>-0.029594</td>\n      <td>-0.051015</td>\n      <td>0.067890</td>\n      <td>...</td>\n      <td>-0.001212</td>\n      <td>-0.005342</td>\n      <td>-0.233871</td>\n      <td>-0.124089</td>\n      <td>0.124338</td>\n      <td>0.284089</td>\n      <td>-0.244712</td>\n      <td>0.168567</td>\n      <td>-0.076076</td>\n      <td>-0.086543</td>\n    </tr>\n    <tr>\n      <th>zophno</th>\n      <td>0.183705</td>\n      <td>-0.059724</td>\n      <td>-0.451903</td>\n      <td>-0.299384</td>\n      <td>0.058367</td>\n      <td>-0.039836</td>\n      <td>0.067061</td>\n      <td>0.238934</td>\n      <td>0.267701</td>\n      <td>-0.052739</td>\n      <td>...</td>\n      <td>0.139718</td>\n      <td>0.125756</td>\n      <td>0.168113</td>\n      <td>0.080182</td>\n      <td>0.112720</td>\n      <td>0.434177</td>\n      <td>-0.110954</td>\n      <td>-0.192290</td>\n      <td>0.096343</td>\n      <td>0.133488</td>\n    </tr>\n    <tr>\n      <th>z7sghp</th>\n      <td>-0.144103</td>\n      <td>-0.134290</td>\n      <td>-0.347879</td>\n      <td>-0.160396</td>\n      <td>-0.153021</td>\n      <td>0.074020</td>\n      <td>-0.274817</td>\n      <td>-0.007368</td>\n      <td>0.148038</td>\n      <td>-0.135822</td>\n      <td>...</td>\n      <td>-0.145126</td>\n      <td>0.029284</td>\n      <td>-0.306107</td>\n      <td>0.214905</td>\n      <td>-0.032107</td>\n      <td>0.199594</td>\n      <td>-0.493793</td>\n      <td>-0.173641</td>\n      <td>-0.092477</td>\n      <td>0.060075</td>\n    </tr>\n    <tr>\n      <th>zodvmd</th>\n      <td>-0.077790</td>\n      <td>-0.151644</td>\n      <td>-0.057777</td>\n      <td>0.015539</td>\n      <td>0.124159</td>\n      <td>-0.127192</td>\n      <td>-0.381995</td>\n      <td>-0.249851</td>\n      <td>0.151266</td>\n      <td>0.159449</td>\n      <td>...</td>\n      <td>-0.049719</td>\n      <td>0.040907</td>\n      <td>-0.141377</td>\n      <td>0.091956</td>\n      <td>-0.027756</td>\n      <td>0.071189</td>\n      <td>-0.137783</td>\n      <td>0.050524</td>\n      <td>-0.203722</td>\n      <td>-0.260013</td>\n    </tr>\n  </tbody>\n</table>\n<p>6477 rows × 300 columns</p>\n</div>"
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2V_model.vectorize(obj.X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4         5         6    \\\nid                                                                             \nzneu4t  0.024756  0.017508 -0.245544 -0.079161  0.141099  0.425426 -0.383731   \nzqdj2z -0.000625  0.000360  0.001490 -0.001408  0.000112 -0.000787  0.000359   \nzsoaht -0.273645 -0.228289 -0.279748 -0.255452  0.641437  0.180611 -0.225046   \nzpb6mm -0.316552 -0.127628 -0.134513  0.232185  0.249365  0.035668 -0.225528   \nzspweu -0.124831  0.069495 -0.500268 -0.328436  0.222820 -0.153912 -0.281175   \n...          ...       ...       ...       ...       ...       ...       ...   \nzqh63h  0.090006  0.078147 -0.342505 -0.209351  0.077070  0.176495 -0.168447   \nzozmfd  0.446083  0.108086 -0.116243 -0.301169  0.115406  0.013130 -0.124489   \nzsmn5w -0.018422 -0.173283  0.053598  0.025485 -0.053987  0.163447 -0.030172   \nyta4a2  0.045882  0.158547 -0.323433  0.114190 -0.055485  0.081891 -0.430319   \nzqg6xg  0.337526  0.078987  0.046910 -0.252965  0.321727  0.267316 -0.126933   \n\n             7         8         9    ...       290       291       292  \\\nid                                    ...                                 \nzneu4t  0.320392  0.369929 -0.004070  ... -0.278416 -0.357967 -0.324445   \nzqdj2z -0.000465  0.000478 -0.000510  ... -0.001632 -0.001583  0.000785   \nzsoaht -0.225095 -0.011575  0.265786  ...  0.044403  0.123269 -0.026987   \nzpb6mm -0.025776  0.085983 -0.002724  ... -0.088556  0.144621 -0.151302   \nzspweu  0.128660 -0.124410 -0.141062  ... -0.376867 -0.108806 -0.102207   \n...          ...       ...       ...  ...       ...       ...       ...   \nzqh63h  0.053810  0.359074 -0.024932  ...  0.021485 -0.013352 -0.016688   \nzozmfd  0.038892  0.269257  0.020708  ... -0.063685 -0.211680  0.072351   \nzsmn5w -0.011530  0.143444  0.160024  ... -0.056186 -0.160709  0.140689   \nyta4a2 -0.038523  0.080145 -0.146721  ... -0.022787  0.102703 -0.125879   \nzqg6xg  0.147363 -0.116318 -0.129978  ...  0.307527  0.360710 -0.373802   \n\n             293       294       295       296       297       298       299  \nid                                                                            \nzneu4t -0.079764  0.312804  0.166880 -0.082328  0.328065 -0.143884 -0.183912  \nzqdj2z  0.001610 -0.001610  0.000617 -0.000850 -0.000598 -0.000673  0.000851  \nzsoaht -0.031384 -0.008669  0.659682  0.065079  0.043444 -0.239513 -0.131342  \nzpb6mm  0.352720  0.141440  0.626190  0.123271  0.179211 -0.457471 -0.166082  \nzspweu -0.082202  0.053004  0.440408 -0.040838  0.061226 -0.162835 -0.175296  \n...          ...       ...       ...       ...       ...       ...       ...  \nzqh63h -0.125820  0.134182 -0.036878 -0.171178  0.098551  0.019160 -0.018199  \nzozmfd -0.124213  0.098303  0.031621 -0.323328  0.284245  0.051450 -0.088354  \nzsmn5w -0.118233  0.107463  0.405808 -0.052695  0.201463 -0.417349 -0.383937  \nyta4a2 -0.235870  0.015697  0.134702  0.041802 -0.008966 -0.146478 -0.150347  \nzqg6xg -0.304602  0.526860 -0.018422 -0.060996  0.166368 -0.258179  0.240033  \n\n[2776 rows x 300 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>zneu4t</th>\n      <td>0.024756</td>\n      <td>0.017508</td>\n      <td>-0.245544</td>\n      <td>-0.079161</td>\n      <td>0.141099</td>\n      <td>0.425426</td>\n      <td>-0.383731</td>\n      <td>0.320392</td>\n      <td>0.369929</td>\n      <td>-0.004070</td>\n      <td>...</td>\n      <td>-0.278416</td>\n      <td>-0.357967</td>\n      <td>-0.324445</td>\n      <td>-0.079764</td>\n      <td>0.312804</td>\n      <td>0.166880</td>\n      <td>-0.082328</td>\n      <td>0.328065</td>\n      <td>-0.143884</td>\n      <td>-0.183912</td>\n    </tr>\n    <tr>\n      <th>zqdj2z</th>\n      <td>-0.000625</td>\n      <td>0.000360</td>\n      <td>0.001490</td>\n      <td>-0.001408</td>\n      <td>0.000112</td>\n      <td>-0.000787</td>\n      <td>0.000359</td>\n      <td>-0.000465</td>\n      <td>0.000478</td>\n      <td>-0.000510</td>\n      <td>...</td>\n      <td>-0.001632</td>\n      <td>-0.001583</td>\n      <td>0.000785</td>\n      <td>0.001610</td>\n      <td>-0.001610</td>\n      <td>0.000617</td>\n      <td>-0.000850</td>\n      <td>-0.000598</td>\n      <td>-0.000673</td>\n      <td>0.000851</td>\n    </tr>\n    <tr>\n      <th>zsoaht</th>\n      <td>-0.273645</td>\n      <td>-0.228289</td>\n      <td>-0.279748</td>\n      <td>-0.255452</td>\n      <td>0.641437</td>\n      <td>0.180611</td>\n      <td>-0.225046</td>\n      <td>-0.225095</td>\n      <td>-0.011575</td>\n      <td>0.265786</td>\n      <td>...</td>\n      <td>0.044403</td>\n      <td>0.123269</td>\n      <td>-0.026987</td>\n      <td>-0.031384</td>\n      <td>-0.008669</td>\n      <td>0.659682</td>\n      <td>0.065079</td>\n      <td>0.043444</td>\n      <td>-0.239513</td>\n      <td>-0.131342</td>\n    </tr>\n    <tr>\n      <th>zpb6mm</th>\n      <td>-0.316552</td>\n      <td>-0.127628</td>\n      <td>-0.134513</td>\n      <td>0.232185</td>\n      <td>0.249365</td>\n      <td>0.035668</td>\n      <td>-0.225528</td>\n      <td>-0.025776</td>\n      <td>0.085983</td>\n      <td>-0.002724</td>\n      <td>...</td>\n      <td>-0.088556</td>\n      <td>0.144621</td>\n      <td>-0.151302</td>\n      <td>0.352720</td>\n      <td>0.141440</td>\n      <td>0.626190</td>\n      <td>0.123271</td>\n      <td>0.179211</td>\n      <td>-0.457471</td>\n      <td>-0.166082</td>\n    </tr>\n    <tr>\n      <th>zspweu</th>\n      <td>-0.124831</td>\n      <td>0.069495</td>\n      <td>-0.500268</td>\n      <td>-0.328436</td>\n      <td>0.222820</td>\n      <td>-0.153912</td>\n      <td>-0.281175</td>\n      <td>0.128660</td>\n      <td>-0.124410</td>\n      <td>-0.141062</td>\n      <td>...</td>\n      <td>-0.376867</td>\n      <td>-0.108806</td>\n      <td>-0.102207</td>\n      <td>-0.082202</td>\n      <td>0.053004</td>\n      <td>0.440408</td>\n      <td>-0.040838</td>\n      <td>0.061226</td>\n      <td>-0.162835</td>\n      <td>-0.175296</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>zqh63h</th>\n      <td>0.090006</td>\n      <td>0.078147</td>\n      <td>-0.342505</td>\n      <td>-0.209351</td>\n      <td>0.077070</td>\n      <td>0.176495</td>\n      <td>-0.168447</td>\n      <td>0.053810</td>\n      <td>0.359074</td>\n      <td>-0.024932</td>\n      <td>...</td>\n      <td>0.021485</td>\n      <td>-0.013352</td>\n      <td>-0.016688</td>\n      <td>-0.125820</td>\n      <td>0.134182</td>\n      <td>-0.036878</td>\n      <td>-0.171178</td>\n      <td>0.098551</td>\n      <td>0.019160</td>\n      <td>-0.018199</td>\n    </tr>\n    <tr>\n      <th>zozmfd</th>\n      <td>0.446083</td>\n      <td>0.108086</td>\n      <td>-0.116243</td>\n      <td>-0.301169</td>\n      <td>0.115406</td>\n      <td>0.013130</td>\n      <td>-0.124489</td>\n      <td>0.038892</td>\n      <td>0.269257</td>\n      <td>0.020708</td>\n      <td>...</td>\n      <td>-0.063685</td>\n      <td>-0.211680</td>\n      <td>0.072351</td>\n      <td>-0.124213</td>\n      <td>0.098303</td>\n      <td>0.031621</td>\n      <td>-0.323328</td>\n      <td>0.284245</td>\n      <td>0.051450</td>\n      <td>-0.088354</td>\n    </tr>\n    <tr>\n      <th>zsmn5w</th>\n      <td>-0.018422</td>\n      <td>-0.173283</td>\n      <td>0.053598</td>\n      <td>0.025485</td>\n      <td>-0.053987</td>\n      <td>0.163447</td>\n      <td>-0.030172</td>\n      <td>-0.011530</td>\n      <td>0.143444</td>\n      <td>0.160024</td>\n      <td>...</td>\n      <td>-0.056186</td>\n      <td>-0.160709</td>\n      <td>0.140689</td>\n      <td>-0.118233</td>\n      <td>0.107463</td>\n      <td>0.405808</td>\n      <td>-0.052695</td>\n      <td>0.201463</td>\n      <td>-0.417349</td>\n      <td>-0.383937</td>\n    </tr>\n    <tr>\n      <th>yta4a2</th>\n      <td>0.045882</td>\n      <td>0.158547</td>\n      <td>-0.323433</td>\n      <td>0.114190</td>\n      <td>-0.055485</td>\n      <td>0.081891</td>\n      <td>-0.430319</td>\n      <td>-0.038523</td>\n      <td>0.080145</td>\n      <td>-0.146721</td>\n      <td>...</td>\n      <td>-0.022787</td>\n      <td>0.102703</td>\n      <td>-0.125879</td>\n      <td>-0.235870</td>\n      <td>0.015697</td>\n      <td>0.134702</td>\n      <td>0.041802</td>\n      <td>-0.008966</td>\n      <td>-0.146478</td>\n      <td>-0.150347</td>\n    </tr>\n    <tr>\n      <th>zqg6xg</th>\n      <td>0.337526</td>\n      <td>0.078987</td>\n      <td>0.046910</td>\n      <td>-0.252965</td>\n      <td>0.321727</td>\n      <td>0.267316</td>\n      <td>-0.126933</td>\n      <td>0.147363</td>\n      <td>-0.116318</td>\n      <td>-0.129978</td>\n      <td>...</td>\n      <td>0.307527</td>\n      <td>0.360710</td>\n      <td>-0.373802</td>\n      <td>-0.304602</td>\n      <td>0.526860</td>\n      <td>-0.018422</td>\n      <td>-0.060996</td>\n      <td>0.166368</td>\n      <td>-0.258179</td>\n      <td>0.240033</td>\n    </tr>\n  </tbody>\n</table>\n<p>2776 rows × 300 columns</p>\n</div>"
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2V_model.vectorize(obj.X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_31196\\1858139291.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mD2V_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvectorize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_titles\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'title'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_31196\\434447820.py\u001B[0m in \u001B[0;36mvectorize\u001B[1;34m(self, df_titles)\u001B[0m\n\u001B[0;32m     17\u001B[0m         \u001B[1;34m\"\"\"Given a data frame or series with only titles, will return a df of all of the features, indexed by id. The actual function will be added to each object.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_vectorize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_titles\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_vectorize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_titles\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_31196\\143658427.py\u001B[0m in \u001B[0;36m_D2V_vectorize\u001B[1;34m(df_titles, model)\u001B[0m\n\u001B[0;32m     19\u001B[0m     \u001B[0mvectors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfer_vector\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtitle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mtitle\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdf_titles\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[0mdf_new\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m'title'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mdf_titles\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'vector'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mvectors\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m     \u001B[0mdf_new\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_new\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'vector'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001B[0m in \u001B[0;36mconcat\u001B[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[0m\n\u001B[0;32m    345\u001B[0m     \u001B[0mValueError\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIndexes\u001B[0m \u001B[0mhave\u001B[0m \u001B[0moverlapping\u001B[0m \u001B[0mvalues\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'a'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    346\u001B[0m     \"\"\"\n\u001B[1;32m--> 347\u001B[1;33m     op = _Concatenator(\n\u001B[0m\u001B[0;32m    348\u001B[0m         \u001B[0mobjs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    349\u001B[0m         \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001B[0m\n\u001B[0;32m    380\u001B[0m     ):\n\u001B[0;32m    381\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobjs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mABCSeries\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mABCDataFrame\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 382\u001B[1;33m             raise TypeError(\n\u001B[0m\u001B[0;32m    383\u001B[0m                 \u001B[1;34m\"first argument must be an iterable of pandas \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    384\u001B[0m                 \u001B[1;34mf'objects, you passed an object of type \"{type(objs).__name__}\"'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\""
     ]
    }
   ],
   "source": [
    "\n",
    "D2V_model.vectorize(test_titles['title'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "           # Create a list of TaggedDocument objects from the titles\n",
    "X_train_tagged = self.X_train.tolist()\n",
    "X_train_tagged = [TaggedDocument(words=title.split(), tags=[str(i)]) for i, title in enumerate(X_train_tagged)]\n",
    "X_test_tagged = self.X_test.tolist()\n",
    "X_test_tagged = [TaggedDocument(words=title.split(), tags=[str(i)]) for i, title in enumerate(X_test_tagged)]\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0)\n",
    "model_dbow.build_vocab(X_train_tagged)\n",
    "\n",
    "# Train the model\n",
    "model_dbow.train(X_train_tagged, total_examples=model_dbow.corpus_count, epochs=100)\n",
    "\n",
    "# Get the vectorized titles from the doc2vec model\n",
    "vectors = [model_dbow.infer_vector(title.split()) for title in X_train.tolist()]\n",
    "\n",
    "# Add the vectors to the dataframe as a new column\n",
    "df_new = pd.DataFrame({'title':X_train, 'vector': vectors})\n",
    "df_new"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [],
   "source": [
    "BoW_model = Title_Vectorizer('BoW')\n",
    "BoW_model._vectorize = _BoW_vectorize\n",
    "BoW_model._train = _BoW_train\n",
    "#BoW_model.train(obj.X_train)\n",
    "#BoW_model.vectorize(obj.X_train)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [
    {
     "data": {
      "text/plain": "sklearn.feature_extraction.text.CountVectorizer"
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#_BoW_train(obj.X_train)\n",
    "BoW_model._train = _BoW_train\n",
    "BoW_model.train(obj.X_train)\n",
    "type(BoW_model.model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [
    {
     "data": {
      "text/plain": "NoneType"
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(BoW_model.model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BoW_model.model.transform(list(test_titles['title'])).toarray()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    I love\n",
      "1    I hate\n",
      "2    I like\n",
      "dtype: object\n",
      "0    I love\n",
      "1    I hate\n",
      "2    I like\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample pandas series\n",
    "s = pd.Series(['I love dogs', 'I hate cats', 'I like turtles'])\n",
    "\n",
    "# Create a vocabulary\n",
    "vocab = ['I', 'love', 'hate', 'like']\n",
    "\n",
    "# Remove words from the sentences that are not in the vocabulary\n",
    "filtered_s = s.apply(lambda x: ' '.join([word for word in x.split() if word in vocab]))\n",
    "\n",
    "# Print the filtered series\n",
    "print(filtered_s)\n",
    "# Remove words from the sentences that are not in the vocabulary\n",
    "filtered_s = s.apply(lambda x: ' '.join(set(x.split()).intersection(vocab)))\n",
    "\n",
    "# Print the filtered series\n",
    "print(filtered_s)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = CountVectorizer()\n",
    "x.fit_transform(obj.X_train)\n",
    "vocab = x.vocabulary_\n",
    "'im' in vocab"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               title\n0  Redditors of Reddit. What is your favorite pie...\n1  WIBTA if I stole my younger brothers lunch money?\n2                  check out this cool video I found\n3                                               asdf\n4                                 cats are dangerous\n5                 new study shows cats are dangerous\n6                                   reddit cool aita",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Redditors of Reddit. What is your favorite pie...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WIBTA if I stole my younger brothers lunch money?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>check out this cool video I found</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>asdf</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cats are dangerous</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>new study shows cats are dangerous</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>reddit cool aita</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_titles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_31196\\1401820855.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mBoW_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvectorize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m'title'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mtest_titles\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_31196\\1647834529.py\u001B[0m in \u001B[0;36mvectorize\u001B[1;34m(self, df_titles)\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[1;34m\"\"\"Given a data frame or series with only titles, will return a df of all of the features, indexed by id. The actual function will be added to each object.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_vectorize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_titles\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_vectorize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_titles\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_31196\\3159065385.py\u001B[0m in \u001B[0;36m_BoW_vectorize\u001B[1;34m(df_titles)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_BoW_vectorize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_titles\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[1;34m\"\"\"I think I need to drop every word that's not in the vocabulary.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[0mdf_titles\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_titles\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m' '\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvocab\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m     \u001B[0mtemp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mCountVectorizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_titles\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtemp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_titles\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[0;32m   8846\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   8847\u001B[0m         )\n\u001B[1;32m-> 8848\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__finalize__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"apply\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   8849\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   8850\u001B[0m     def applymap(\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    731\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_raw\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    732\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 733\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_standard\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    734\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    735\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0magg\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    855\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    856\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_standard\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 857\u001B[1;33m         \u001B[0mresults\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mres_index\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_series_generator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    858\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    859\u001B[0m         \u001B[1;31m# wrap results\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply_series_generator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    871\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseries_gen\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    872\u001B[0m                 \u001B[1;31m# ignore SettingWithCopy here in case the user mutates\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 873\u001B[1;33m                 \u001B[0mresults\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    874\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresults\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mABCSeries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    875\u001B[0m                     \u001B[1;31m# If we have a view on v, we need to make a copy because\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_31196\\3159065385.py\u001B[0m in \u001B[0;36m<lambda>\u001B[1;34m(s)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_BoW_vectorize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_titles\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[1;34m\"\"\"I think I need to drop every word that's not in the vocabulary.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[0mdf_titles\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_titles\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m' '\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvocab\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m     \u001B[0mtemp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mCountVectorizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_titles\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtemp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_titles\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   5573\u001B[0m         ):\n\u001B[0;32m   5574\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5575\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   5576\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5577\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__setattr__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Series' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "BoW_model.vectorize(pd.DataFrame({'title':test_titles}))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6477 entries, zmng91 to zodvmd\n",
      "Columns: 13136 entries, 0 to 13135\n",
      "dtypes: int64(13136)\n",
      "memory usage: 649.4+ MB\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(x, obj.X_train.index).info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_31196\\3540296549.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m'title'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'vector'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    634\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    635\u001B[0m             \u001B[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 636\u001B[1;33m             \u001B[0mmgr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdict_to_mgr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtyp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmanager\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    637\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMaskedArray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    638\u001B[0m             \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmrecords\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mmrecords\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36mdict_to_mgr\u001B[1;34m(data, index, columns, dtype, typ, copy)\u001B[0m\n\u001B[0;32m    500\u001B[0m         \u001B[1;31m# TODO: can we get rid of the dt64tz special case above?\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    501\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 502\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0marrays_to_mgr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtyp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtyp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconsolidate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    503\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    504\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36marrays_to_mgr\u001B[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001B[0m\n\u001B[0;32m    118\u001B[0m         \u001B[1;31m# figure out the index, if necessary\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    119\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mindex\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 120\u001B[1;33m             \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_extract_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    121\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    122\u001B[0m             \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mensure_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36m_extract_index\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    659\u001B[0m                 \u001B[0mraw_lengths\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    660\u001B[0m             \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mval\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 661\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Per-column arrays must each be 1-dimensional\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    662\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    663\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mindexes\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mraw_lengths\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({'title':obj.X_train, 'vector': x})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "outputs": [],
   "source": [
    "obj = Subreddit_Predictor()\n",
    "obj.add_data(df)\n",
    "obj.clean_data()\n",
    "obj.ready_data(test_size=.3, seed=29)\n",
    "obj.add_title_vectorizer(BoW_model)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [
    {
     "data": {
      "text/plain": "        0      1      2      3      4      5      6      7      8      9      \\\nid                                                                             \nzmng91      0      0      0      0      0      0      0      0      0      0   \nzrve0c      0      0      0      0      0      0      0      0      0      0   \nzppddb      0      0      0      0      0      0      0      0      0      0   \nz4m4c6      0      0      0      0      0      0      0      0      0      0   \nzeb9r7      0      0      0      0      0      0      0      0      0      0   \n...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \nzo36za      0      0      0      0      0      0      0      0      0      0   \nzog02f      0      0      0      0      0      0      0      0      0      0   \nzophno      0      0      0      0      0      0      0      0      0      0   \nz7sghp      0      0      0      0      0      0      0      0      0      0   \nzodvmd      0      0      0      0      0      0      0      0      0      0   \n\n        ...  13126  13127  13128  13129  13130  13131  13132  13133  13134  \\\nid      ...                                                                  \nzmng91  ...      0      0      0      0      0      0      0      0      0   \nzrve0c  ...      0      0      0      0      0      0      0      0      0   \nzppddb  ...      0      0      0      0      0      0      0      0      0   \nz4m4c6  ...      0      0      0      0      0      0      0      0      0   \nzeb9r7  ...      0      0      0      0      0      0      0      0      0   \n...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \nzo36za  ...      0      0      0      0      0      0      0      0      0   \nzog02f  ...      0      0      0      0      0      0      0      0      0   \nzophno  ...      0      0      0      0      0      0      0      0      0   \nz7sghp  ...      0      0      0      0      0      0      0      0      0   \nzodvmd  ...      0      0      0      0      0      0      0      0      0   \n\n        13135  \nid             \nzmng91      0  \nzrve0c      0  \nzppddb      0  \nz4m4c6      0  \nzeb9r7      0  \n...       ...  \nzo36za      0  \nzog02f      0  \nzophno      0  \nz7sghp      0  \nzodvmd      0  \n\n[6477 rows x 13136 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>13126</th>\n      <th>13127</th>\n      <th>13128</th>\n      <th>13129</th>\n      <th>13130</th>\n      <th>13131</th>\n      <th>13132</th>\n      <th>13133</th>\n      <th>13134</th>\n      <th>13135</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>zmng91</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>zrve0c</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>zppddb</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>z4m4c6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>zeb9r7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>zo36za</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>zog02f</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>zophno</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>z7sghp</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>zodvmd</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6477 rows × 13136 columns</p>\n</div>"
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.Feature_Vectors['BoW']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 2\n"
     ]
    }
   ],
   "source": [
    "def foo(x):\n",
    "    print ('hello',x)\n",
    "\n",
    "obj.fun = foo\n",
    "\n",
    "obj.fun(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "          id                                              title      subreddit\n0     t93ec3  This subreddit is closed for new posts and com...  announcements\n1     pg006s          COVID denialism and policy clarifications  announcements\n2     pbmy5y             Debate, dissent, and protest on Reddit  announcements\n3     nw2hs6           Sunsetting Secret Santa and Reddit Gifts  announcements\n4     mi01fg                                             Second  announcements\n...      ...                                                ...            ...\n9261  zq0n2b               WIBTA For Exposing My Dad to My Mom?  AmItheAsshole\n9262  zq0kzb  AITA for trying to rescue/take home/whatever a...  AmItheAsshole\n9263  zq0kv9  AITA for not wanting to gift hotel soaps for C...  AmItheAsshole\n9264  zq0k55          AITA for walking my dog on my own street?  AmItheAsshole\n9265  zq0i4t  WIBTA if I called my cat with a nickname rathe...  AmItheAsshole\n\n[9266 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>subreddit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>t93ec3</td>\n      <td>This subreddit is closed for new posts and com...</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pg006s</td>\n      <td>COVID denialism and policy clarifications</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pbmy5y</td>\n      <td>Debate, dissent, and protest on Reddit</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>nw2hs6</td>\n      <td>Sunsetting Secret Santa and Reddit Gifts</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mi01fg</td>\n      <td>Second</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9261</th>\n      <td>zq0n2b</td>\n      <td>WIBTA For Exposing My Dad to My Mom?</td>\n      <td>AmItheAsshole</td>\n    </tr>\n    <tr>\n      <th>9262</th>\n      <td>zq0kzb</td>\n      <td>AITA for trying to rescue/take home/whatever a...</td>\n      <td>AmItheAsshole</td>\n    </tr>\n    <tr>\n      <th>9263</th>\n      <td>zq0kv9</td>\n      <td>AITA for not wanting to gift hotel soaps for C...</td>\n      <td>AmItheAsshole</td>\n    </tr>\n    <tr>\n      <th>9264</th>\n      <td>zq0k55</td>\n      <td>AITA for walking my dog on my own street?</td>\n      <td>AmItheAsshole</td>\n    </tr>\n    <tr>\n      <th>9265</th>\n      <td>zq0i4t</td>\n      <td>WIBTA if I called my cat with a nickname rathe...</td>\n      <td>AmItheAsshole</td>\n    </tr>\n  </tbody>\n</table>\n<p>9266 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert the labels to numerical values\n",
    "le = LabelEncoder()\n",
    "df['subreddit_num'] = le.fit_transform(df['subreddit'])\n",
    "\n",
    "df = df.drop(columns=['subreddit'])\n",
    "\n",
    "#df['subreddit'] = le.inverse_transform(df['subreddit_num'])\n",
    "\n",
    "df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame({'id':['pg006s'], 'title':[a], 'subreddit':['announcements']}).set_index('id')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    title      subreddit\nid                                                                      \npg006s          COVID denialism and policy clarifications  announcements\npbmy5y             Debate, dissent, and protest on Reddit  announcements\nnw2hs6           Sunsetting Secret Santa and Reddit Gifts  announcements\nmi01fg                                             Second  announcements\nmcisdf  An update on the recent issues surrounding a R...  announcements\n...                                                   ...            ...\nzq0n2b               WIBTA For Exposing My Dad to My Mom?  AmItheAsshole\nzq0kzb  AITA for trying to rescue/take home/whatever a...  AmItheAsshole\nzq0kv9  AITA for not wanting to gift hotel soaps for C...  AmItheAsshole\nzq0k55          AITA for walking my dog on my own street?  AmItheAsshole\nzq0i4t  WIBTA if I called my cat with a nickname rathe...  AmItheAsshole\n\n[9160 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>subreddit</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>pg006s</th>\n      <td>COVID denialism and policy clarifications</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>pbmy5y</th>\n      <td>Debate, dissent, and protest on Reddit</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>nw2hs6</th>\n      <td>Sunsetting Secret Santa and Reddit Gifts</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>mi01fg</th>\n      <td>Second</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>mcisdf</th>\n      <td>An update on the recent issues surrounding a R...</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>zq0n2b</th>\n      <td>WIBTA For Exposing My Dad to My Mom?</td>\n      <td>AmItheAsshole</td>\n    </tr>\n    <tr>\n      <th>zq0kzb</th>\n      <td>AITA for trying to rescue/take home/whatever a...</td>\n      <td>AmItheAsshole</td>\n    </tr>\n    <tr>\n      <th>zq0kv9</th>\n      <td>AITA for not wanting to gift hotel soaps for C...</td>\n      <td>AmItheAsshole</td>\n    </tr>\n    <tr>\n      <th>zq0k55</th>\n      <td>AITA for walking my dog on my own street?</td>\n      <td>AmItheAsshole</td>\n    </tr>\n    <tr>\n      <th>zq0i4t</th>\n      <td>WIBTA if I called my cat with a nickname rathe...</td>\n      <td>AmItheAsshole</td>\n    </tr>\n  </tbody>\n</table>\n<p>9160 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_new, df]).drop_duplicates(keep = False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    title      subreddit\nid                                                                      \nt93ec3  This subreddit is closed for new posts and com...  announcements\npg006s          COVID denialism and policy clarifications  announcements\npbmy5y             Debate, dissent, and protest on Reddit  announcements\nnw2hs6           Sunsetting Secret Santa and Reddit Gifts  announcements\nmi01fg                                             Second  announcements\n...                                                   ...            ...\nzq0n2b               WIBTA For Exposing My Dad to My Mom?  AmItheAsshole\nzq0kzb  AITA for trying to rescue/take home/whatever a...  AmItheAsshole\nzq0kv9  AITA for not wanting to gift hotel soaps for C...  AmItheAsshole\nzq0k55          AITA for walking my dog on my own street?  AmItheAsshole\nzq0i4t  WIBTA if I called my cat with a nickname rathe...  AmItheAsshole\n\n[9210 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>subreddit</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>t93ec3</th>\n      <td>This subreddit is closed for new posts and com...</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>pg006s</th>\n      <td>COVID denialism and policy clarifications</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>pbmy5y</th>\n      <td>Debate, dissent, and protest on Reddit</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>nw2hs6</th>\n      <td>Sunsetting Secret Santa and Reddit Gifts</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>mi01fg</th>\n      <td>Second</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>zq0n2b</th>\n      <td>WIBTA For Exposing My Dad to My Mom?</td>\n      <td>AmItheAsshole</td>\n    </tr>\n    <tr>\n      <th>zq0kzb</th>\n      <td>AITA for trying to rescue/take home/whatever a...</td>\n      <td>AmItheAsshole</td>\n    </tr>\n    <tr>\n      <th>zq0kv9</th>\n      <td>AITA for not wanting to gift hotel soaps for C...</td>\n      <td>AmItheAsshole</td>\n    </tr>\n    <tr>\n      <th>zq0k55</th>\n      <td>AITA for walking my dog on my own street?</td>\n      <td>AmItheAsshole</td>\n    </tr>\n    <tr>\n      <th>zq0i4t</th>\n      <td>WIBTA if I called my cat with a nickname rathe...</td>\n      <td>AmItheAsshole</td>\n    </tr>\n  </tbody>\n</table>\n<p>9210 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(keep = 'first')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "2  2  5  8\n",
      "4  3  6  9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({'A': [1, 2, 2, 3, 3], 'B': [4, 5, 5, 6, 6], 'C': [7, 8, 8, 9, 9]})\n",
    "\n",
    "# Find duplicate rows\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "\n",
    "# Print the duplicate rows\n",
    "print(duplicate_rows)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    title      subreddit\nid                                                                      \nc0gl6   We are aware that reddit appears hung over, an...  announcements\nzsrwxs                   What made you want to have kids?      AskReddit\nzspw41                    What do you want for Christmas?      AskReddit\nzsppnr                   What made you want to have kids?      AskReddit\nzspbbv                    What do you want for Christmas?      AskReddit\nzsp834                   What made you want to have kids?      AskReddit\nzso4w7                What is on your Christmas wishlist?      AskReddit\nzso42r  People who have their desserts before their ma...      AskReddit\nzshreq  does crashing and desabling gpu driver means t...         gaming\nzs6y9p        Kingdoms of Amalur: Re-Reckoning worth $12?         gaming\nzml7qc                                              Cutie           Awww\nytaqyj                                                cat           Awww\nxxyrri     In a world where you can be anything, be kind.           Awww\nxuxlzv                                               awww           Awww\nxuco6g                                               Awww           Awww\nxr6c8n                                              Awwww           Awww\nzsduwh  \"3DOG - goodbye girl <3\" Go check me out and g...          Music\nzqi1ll                            Cameron Coyle on TikTok          Music\nzq63z8  Terry Hall: lead singer of the Specials dies a...          Music\nzq19h8              W0lfgxng - terminator [hiphop] (2022)          Music\nzpq77e                                                  🎅          Music\nzpq641                                                  🎅          Music\nzsc4e8                           My 7 year old drew this.           pics\nzrhjbz                             View from my backyard.           pics\nzrgaqa  Iranians are preparing to celebrate Yalda Nigh...           pics\nzr1t8l                              Marker on canvas [OC]           pics\nzq5wao                              Marker on canvas [OC]           pics\nzq5nfg                         I took a picture of a Lake           pics\nzsstby  Official in Russian-controlled Ukraine region ...      worldnews\nzspaem  US says Russia's Wagner Group bought North Kor...      worldnews\nzso92e  U.S. military aid for Ukraine: Five key weapon...      worldnews\nzsjkye  Pope warns Vatican staff an 'elegant demon' lu...      worldnews\nzsh0lo  Kremlin-backed hackers targeted a “large” petr...      worldnews\nzrxeq9  Russian ammunition storage points in Kadiivka ...      worldnews\nzrteq8  Ukraine war: Russia not to blame for conflict ...      worldnews\nzrs1dg  'We will find you:' Russians hunt down Ukraini...      worldnews\nzrkqq8  'We will find you:' Russians hunt down Ukraini...      worldnews\nzrjwo8  Brexit rule that makes EU citizens reapply to ...      worldnews\nzreq86  Hearses queue at Beijing crematorium, even as ...      worldnews\nzr8cez  Kremlin-backed hackers targeted a “large” petr...      worldnews\nzqu5fe  More Iranians face possible execution as autho...      worldnews\nzq43ig  Ukraine to boost Belarus border defences as Pu...      worldnews\nzptekm  Pakistani Taliban overpower guards, seize poli...      worldnews\nzpkg3o  Thailand warship capsizes leaving 31 sailors m...      worldnews\nzo6yec  Brixton Academy: Woman dies after Asake concer...      worldnews\nzo2shg  Hundreds of tourists stranded in Machu Picchu ...      worldnews\nzny8f5  Iranian government accused of 'sham trials' an...      worldnews\nzns4lr  South Korea protests Japan's new security docu...      worldnews\nzna1tr  Russia launches another major missile attack o...      worldnews\nzmln5m  Dutch chip equipment maker ASML's CEO question...      worldnews\nzmj7kd  Ukrainian photographers Yevhen Maloletka and M...      worldnews\nzmhdkd  Irish soldier on UN duty killed in Lebanon attack      worldnews\nzmgocl  Home-grown supply operation outfits Ukraine's ...      worldnews\nzrybuv                This Place Rules (Official Trailer)         videos\nzqn96m  Alice In Chains - Again\" & \"God Am [Tiger Stad...         videos\nzntpi1            Investigating Logan Paul's Biggest Scam         videos",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>subreddit</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>c0gl6</th>\n      <td>We are aware that reddit appears hung over, an...</td>\n      <td>announcements</td>\n    </tr>\n    <tr>\n      <th>zsrwxs</th>\n      <td>What made you want to have kids?</td>\n      <td>AskReddit</td>\n    </tr>\n    <tr>\n      <th>zspw41</th>\n      <td>What do you want for Christmas?</td>\n      <td>AskReddit</td>\n    </tr>\n    <tr>\n      <th>zsppnr</th>\n      <td>What made you want to have kids?</td>\n      <td>AskReddit</td>\n    </tr>\n    <tr>\n      <th>zspbbv</th>\n      <td>What do you want for Christmas?</td>\n      <td>AskReddit</td>\n    </tr>\n    <tr>\n      <th>zsp834</th>\n      <td>What made you want to have kids?</td>\n      <td>AskReddit</td>\n    </tr>\n    <tr>\n      <th>zso4w7</th>\n      <td>What is on your Christmas wishlist?</td>\n      <td>AskReddit</td>\n    </tr>\n    <tr>\n      <th>zso42r</th>\n      <td>People who have their desserts before their ma...</td>\n      <td>AskReddit</td>\n    </tr>\n    <tr>\n      <th>zshreq</th>\n      <td>does crashing and desabling gpu driver means t...</td>\n      <td>gaming</td>\n    </tr>\n    <tr>\n      <th>zs6y9p</th>\n      <td>Kingdoms of Amalur: Re-Reckoning worth $12?</td>\n      <td>gaming</td>\n    </tr>\n    <tr>\n      <th>zml7qc</th>\n      <td>Cutie</td>\n      <td>Awww</td>\n    </tr>\n    <tr>\n      <th>ytaqyj</th>\n      <td>cat</td>\n      <td>Awww</td>\n    </tr>\n    <tr>\n      <th>xxyrri</th>\n      <td>In a world where you can be anything, be kind.</td>\n      <td>Awww</td>\n    </tr>\n    <tr>\n      <th>xuxlzv</th>\n      <td>awww</td>\n      <td>Awww</td>\n    </tr>\n    <tr>\n      <th>xuco6g</th>\n      <td>Awww</td>\n      <td>Awww</td>\n    </tr>\n    <tr>\n      <th>xr6c8n</th>\n      <td>Awwww</td>\n      <td>Awww</td>\n    </tr>\n    <tr>\n      <th>zsduwh</th>\n      <td>\"3DOG - goodbye girl &lt;3\" Go check me out and g...</td>\n      <td>Music</td>\n    </tr>\n    <tr>\n      <th>zqi1ll</th>\n      <td>Cameron Coyle on TikTok</td>\n      <td>Music</td>\n    </tr>\n    <tr>\n      <th>zq63z8</th>\n      <td>Terry Hall: lead singer of the Specials dies a...</td>\n      <td>Music</td>\n    </tr>\n    <tr>\n      <th>zq19h8</th>\n      <td>W0lfgxng - terminator [hiphop] (2022)</td>\n      <td>Music</td>\n    </tr>\n    <tr>\n      <th>zpq77e</th>\n      <td>🎅</td>\n      <td>Music</td>\n    </tr>\n    <tr>\n      <th>zpq641</th>\n      <td>🎅</td>\n      <td>Music</td>\n    </tr>\n    <tr>\n      <th>zsc4e8</th>\n      <td>My 7 year old drew this.</td>\n      <td>pics</td>\n    </tr>\n    <tr>\n      <th>zrhjbz</th>\n      <td>View from my backyard.</td>\n      <td>pics</td>\n    </tr>\n    <tr>\n      <th>zrgaqa</th>\n      <td>Iranians are preparing to celebrate Yalda Nigh...</td>\n      <td>pics</td>\n    </tr>\n    <tr>\n      <th>zr1t8l</th>\n      <td>Marker on canvas [OC]</td>\n      <td>pics</td>\n    </tr>\n    <tr>\n      <th>zq5wao</th>\n      <td>Marker on canvas [OC]</td>\n      <td>pics</td>\n    </tr>\n    <tr>\n      <th>zq5nfg</th>\n      <td>I took a picture of a Lake</td>\n      <td>pics</td>\n    </tr>\n    <tr>\n      <th>zsstby</th>\n      <td>Official in Russian-controlled Ukraine region ...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zspaem</th>\n      <td>US says Russia's Wagner Group bought North Kor...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zso92e</th>\n      <td>U.S. military aid for Ukraine: Five key weapon...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zsjkye</th>\n      <td>Pope warns Vatican staff an 'elegant demon' lu...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zsh0lo</th>\n      <td>Kremlin-backed hackers targeted a “large” petr...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zrxeq9</th>\n      <td>Russian ammunition storage points in Kadiivka ...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zrteq8</th>\n      <td>Ukraine war: Russia not to blame for conflict ...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zrs1dg</th>\n      <td>'We will find you:' Russians hunt down Ukraini...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zrkqq8</th>\n      <td>'We will find you:' Russians hunt down Ukraini...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zrjwo8</th>\n      <td>Brexit rule that makes EU citizens reapply to ...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zreq86</th>\n      <td>Hearses queue at Beijing crematorium, even as ...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zr8cez</th>\n      <td>Kremlin-backed hackers targeted a “large” petr...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zqu5fe</th>\n      <td>More Iranians face possible execution as autho...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zq43ig</th>\n      <td>Ukraine to boost Belarus border defences as Pu...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zptekm</th>\n      <td>Pakistani Taliban overpower guards, seize poli...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zpkg3o</th>\n      <td>Thailand warship capsizes leaving 31 sailors m...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zo6yec</th>\n      <td>Brixton Academy: Woman dies after Asake concer...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zo2shg</th>\n      <td>Hundreds of tourists stranded in Machu Picchu ...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zny8f5</th>\n      <td>Iranian government accused of 'sham trials' an...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zns4lr</th>\n      <td>South Korea protests Japan's new security docu...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zna1tr</th>\n      <td>Russia launches another major missile attack o...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zmln5m</th>\n      <td>Dutch chip equipment maker ASML's CEO question...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zmj7kd</th>\n      <td>Ukrainian photographers Yevhen Maloletka and M...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zmhdkd</th>\n      <td>Irish soldier on UN duty killed in Lebanon attack</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zmgocl</th>\n      <td>Home-grown supply operation outfits Ukraine's ...</td>\n      <td>worldnews</td>\n    </tr>\n    <tr>\n      <th>zrybuv</th>\n      <td>This Place Rules (Official Trailer)</td>\n      <td>videos</td>\n    </tr>\n    <tr>\n      <th>zqn96m</th>\n      <td>Alice In Chains - Again\" &amp; \"God Am [Tiger Stad...</td>\n      <td>videos</td>\n    </tr>\n    <tr>\n      <th>zntpi1</th>\n      <td>Investigating Logan Paul's Biggest Scam</td>\n      <td>videos</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
