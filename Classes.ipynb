{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import secrets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class: Subreddit_Predictor\n",
    "\n",
    "Objects of this class contain attributes and Methods that can be broken up into three categories: **Data**, **Collections**, and **Processing**\n",
    "\n",
    "## Data\n",
    "Pandas DataFrames and methods to update and clean the data.\n",
    "\n",
    "**Attributes:**\n",
    "\n",
    "| Name      |   Type    |             Description             |\n",
    "|:----------|:---------:|:-----------------------------------|\n",
    "| raw_data  | DataFrame |      The raw unprocessed data       |\n",
    "| full_data | DataFrame |         The processed data          |\n",
    "| subreddits |   list    | A list of subreddits. Extraced from full_data. |\n",
    "| X_train   | pd.Series | the X portion of the training data  |\n",
    "| Y_train   | np.array  | the Y portion of the training data  |\n",
    "| X_test    | pd.Series |   the X portion of the test data    |\n",
    "| Y_test    | np.array  |   the Y portion of the test data    |\n",
    "\n",
    "**Methods:**\n",
    "\n",
    "| Name (with input/output typing) | Description                                                                                                                               |\n",
    "|---------------------------------| ------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| add_data(df: DataFrame)         | Updates the raw_data attribute                                                                                                            |\n",
    "| ready_data()                    | Cleans the data and does a test train split. <br/> Overwrites the full_data attribute. <br/> Creates the X_train, Y_train, X_test, and Y_test attributes. |\n",
    "\n",
    "## Collections\n",
    "Contains dictionaries of vectorizers, classifiers, and models\n",
    "\n",
    "**Attributes:**\n",
    "\n",
    "| Name        | Type                  | Description                                                                                                                                |\n",
    "|:------------|:----------------------|:-------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Vectorizers | dict | Dictionary of Vectorizer objects                                                                                                           |\n",
    "| Feature_Vectors | dict | Dictionary of the vectorized full_data |\n",
    "| Classifiers | dict | Dictionary of Classifier objects                                                                                                           |\n",
    "| Models      | dict | Dictionary of trained Classifier objects                                                                                                   |\n",
    "| Models_info | dict        | Dictionary containing a description of each model in Models.                                                                               |\n",
    "| Predictions | DataFrame   | A DataFrame with all the titles and actual subreddits in X_test and Y_test <br/> There is a column for each model that has the predictions |\n",
    "| Results | dict | Dictionary of DataFrames for each model. Each row and column is a subreddit. Shows the number of false classifications |\n",
    "\n",
    "**Methods:**\n",
    "\n",
    "| Name (with input/output typing)                                                                                  | Description                                                                                                                                                                                |\n",
    "|------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| add_vectorizer(model: Vectorizer)                                                                                | Trains the vectorizer. <br/>Adds (key = model.name, value = model) to Vectorizers                                                                                                               |\n",
    "| add_feature_vectors(vectorizerName: str)| Embeds X_train as vectors and creates a dataframe for the new feature vectors. <br/> Adds this dataFrame to Feature_Vectors |\n",
    "| add_classifier(model: Classifier)                                                                                | Adds (key = model.name, value = model) to Classifiers                                                                                                                                      |\n",
    "| train_model(<br/>modelName: str, <br/>vectorizerName: str, <br/>classifierName: str, <br/>description = '' :str) | Takes vectorizer and classifer from Vectorizers and Classifiers. <br/>Trains the classifier.<br/>Names and adds the trained model to Models.<br/>Adds the description text to Models_info. |\n",
    "| test_model(modelName: str) | Runs the model against X_test and Y_test. <br/> Updates Predictions and Results                                                                                                            |\n",
    "\n",
    "## Processing\n",
    "\n",
    "**Methods:**\n",
    "\n",
    "| Name (with input/output typing)                       | Description                                                                                   |\n",
    "|-------------------------------------------------------|-----------------------------------------------------------------------------------------------|\n",
    "| predict(modelName:str, title: str, titles: iter[str]) | Given a model, enter a title or a list/dataframe of titles. Will return the model prediction. |\n",
    "| compare(models: list[str])                            | Creates a bar chart comparing each of the models on each of the subreddits. |                  |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Subreddit_Predictor:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        #Data\n",
    "        self.raw_data = pd.DataFrame({'id': [], 'title': [], 'subreddit': []})\n",
    "        self.full_data = pd.DataFrame({'id': [], 'title': [], 'subreddit': []}).set_index('id')\n",
    "        self.subreddits = []\n",
    "\n",
    "        #Collections\n",
    "        self.Vectorizers = {}\n",
    "        self.Feature_Vectors = {}\n",
    "        self.Classifiers = {}\n",
    "        self.Models = {}\n",
    "        self.Models_info = {}\n",
    "        #self.Predictions = {}\n",
    "        self.Results = {}\n",
    "\n",
    "    #### Data ####\n",
    "\n",
    "    def add_data(self, df):\n",
    "        \"\"\"df is a pandas DataFrame with columns={'title':[], 'subreddit':[]}. It will be merged with the existing raw_data\"\"\"\n",
    "        self.raw_data = pd.concat([self.raw_data, df]).drop_duplicates(subset='id')\n",
    "\n",
    "    def ready_data(self, test_size=.2, seed=42):\n",
    "        \"\"\"Splits and encodes the data. Saves is in X_train, Y_train, X_test, Y_test.\"\"\"\n",
    "\n",
    "        # Clean the data\n",
    "        self._clean_data()\n",
    "\n",
    "        # Update the subreddits attribute\n",
    "        self.subreddits = self.full_data['subreddit'].unique().tolist()\n",
    "\n",
    "        # Encode the subreddits\n",
    "        self._le = LabelEncoder()\n",
    "        self.full_data['subreddit_num'] = self._le.fit_transform(self.full_data['subreddit'])\n",
    "\n",
    "        # Split the data\n",
    "        self.X_train, self.X_test, self.Y_train, self.Y_test = train_test_split(self.full_data['title'],\n",
    "                                                                                self._le.fit_transform(\n",
    "                                                                                    self.full_data['subreddit']),\n",
    "                                                                                test_size=test_size, random_state=seed)\n",
    "        # Record the indices\n",
    "        self._train_index = self.X_train.index\n",
    "        self._test_index = self.X_test.index\n",
    "\n",
    "        # Update Predictions\n",
    "        df = self.full_data\n",
    "        df = df.drop(columns=['subreddit_num'])\n",
    "        df = df.loc[obj._test_index]\n",
    "        df = df.rename(columns={'subreddit': 'actual'})\n",
    "        self.Predictions = df\n",
    "\n",
    "    def _clean_data(self):\n",
    "        \"\"\"Cleans the data in raw_data and updates self.data\"\"\"\n",
    "\n",
    "        df = self.raw_data\n",
    "\n",
    "        # Remove all non-alpha-numeric characters\n",
    "        df['title'] = df['title'].str.replace(r'[^a-zA-Z0-9 ]', '', regex=True)\n",
    "\n",
    "        # Make all the text lowercase\n",
    "        df['title'] = df['title'].str.lower()\n",
    "\n",
    "        # Remove empty rows\n",
    "        df['title'] = df['title'].str.strip()\n",
    "        filter = df['title'] == ''\n",
    "        df = df.drop(df[filter].index)\n",
    "\n",
    "        # Store it as\n",
    "        self.full_data = df\n",
    "\n",
    "        # Change the index\n",
    "        self.full_data = self.full_data.set_index('id')\n",
    "\n",
    "    #### Collections ####\n",
    "\n",
    "    def add_vectorizer(self, vectorizer):\n",
    "        \"\"\"This is how we add a vectorizers to our collection\"\"\"\n",
    "        vectorizer.train(self.X_train)\n",
    "        self.Vectorizers[vectorizer.vectorizerName] = vectorizer\n",
    "\n",
    "    def add_feature_vectors(self, vectorizerName):\n",
    "        \"\"\"Updates Feature_Vectors\"\"\"\n",
    "        vectorizer = self.Vectorizers[vectorizerName]\n",
    "        self.Feature_Vectors[vectorizerName] = vectorizer.embed(self.full_data['title'])\n",
    "\n",
    "    def add_classifier(self, classifier):\n",
    "        \"\"\"We add the classifier to our collection, self.Classifiers\"\"\"\n",
    "        self.Classifiers[classifier.classifierName] = classifier\n",
    "\n",
    "    def train_model(self, modelName, vectorizerName, classifierName, description=''):\n",
    "        \"\"\"\n",
    "        :param modelName: The name of this model\n",
    "        :param vectorizerName: Which feature vectors are we using?\n",
    "        :param classifierName: Which classifier are we using?\n",
    "        :param description: Write a short discription of the model (optional).\n",
    "        :return: Adds a trained object of the classifier class to self.Models\n",
    "        \"\"\"\n",
    "\n",
    "        self.Models_info[modelName] = {'vectorizerName': vectorizerName, 'classifierName': classifierName,\n",
    "                                       'description': description}\n",
    "\n",
    "        X_train = self.Feature_Vectors[vectorizerName].loc[self._train_index]\n",
    "        Y_train = self.Y_train\n",
    "        classifier = self.Classifiers[classifierName]\n",
    "        classifier.train(X_train, Y_train)\n",
    "\n",
    "        self.Models[modelName] = classifier\n",
    "\n",
    "    def test_model(self, modelName):\n",
    "        \"\"\"Tests the model using X_test and Y_test. Updates Predictions and Results\"\"\"\n",
    "\n",
    "        model = self.Models[modelName]\n",
    "\n",
    "        vectorizerName = self.Models_info[modelName]['vectorizerName']\n",
    "        X_test = self.Feature_Vectors[vectorizerName].loc[self._test_index]\n",
    "\n",
    "        yhat = model.predict(X_test)\n",
    "        yhat = self._le.inverse_transform(yhat)\n",
    "        self.Predictions[modelName] = yhat\n",
    "\n",
    "        df = self.Predictions\n",
    "        results_matrix = pd.DataFrame(columns=self.subreddits)\n",
    "        for actual_sub in self.subreddits:\n",
    "            row = []\n",
    "            filter = df['actual'] == actual_sub\n",
    "            temp_df = df[filter]\n",
    "            total = len(temp_df)\n",
    "            for predicted_sub in self.subreddits:\n",
    "                filter = temp_df[modelName] == predicted_sub\n",
    "                count = len(temp_df[filter])\n",
    "                row.append(count / total)\n",
    "\n",
    "                #print('actual_sub', actual_sub, 'predicted_sub', predicted_sub)\n",
    "\n",
    "            results_matrix.loc[actual_sub] = row\n",
    "\n",
    "        self.Results[modelName] = results_matrix\n",
    "\n",
    "    #### Processing ####\n",
    "\n",
    "    def predict(self, modelName, titles):\n",
    "        \"\"\"\n",
    "        :param modelName: Which model are we using?\n",
    "        :param titles: A list or series of titles\n",
    "        :return: A data frame of 'title' and 'prediction'\n",
    "        \"\"\"\n",
    "\n",
    "        model = self.Models[modelName]\n",
    "\n",
    "        vectorizerName = self.Models_info[modelName]['vectorizerName']\n",
    "        vectorizer = self.Vectorizers[vectorizerName]\n",
    "\n",
    "        title_vectors = vectorizer.embed(titles)\n",
    "\n",
    "        array = model.predict(title_vectors)\n",
    "        df = pd.DataFrame(array)\n",
    "        df['title'] = titles\n",
    "        df['prediction'] = self._le.inverse_transform(array)\n",
    "        df = df.drop(columns=[0])\n",
    "        return df\n",
    "\n",
    "    def compare(self, list_of_models):\n",
    "        \"\"\"Creates a bar chart comparing the predictions from a list of models\"\"\"\n",
    "\n",
    "        num_models = len(list_of_models)\n",
    "\n",
    "        # Set the width of the bars\n",
    "        bar_width = 1 / (num_models + 1)\n",
    "\n",
    "        #Results = self.Results\n",
    "        Results = {key:self.Results[key] for key in list_of_models}\n",
    "\n",
    "        keys = list(list(Results.items())[0][1].keys())\n",
    "        x_pos = [i for i, _ in enumerate(keys)]\n",
    "\n",
    "        for key, val in Results.items():\n",
    "            correct = []\n",
    "            for sub in self.subreddits: correct.append(val.loc[sub][sub])\n",
    "            plt.bar(x_pos, correct, bar_width, label=key)\n",
    "            x_pos = [i + bar_width for i in x_pos]\n",
    "\n",
    "        x_pos = [i - bar_width for i in x_pos]\n",
    "\n",
    "        # Set the x-axis tick labels\n",
    "        plt.xticks(x_pos, keys, rotation=45, ha='right')\n",
    "\n",
    "        # Add a title and axis labels\n",
    "        plt.title('Which Subreddits were easiest to predict?')\n",
    "        plt.xlabel('Subreddit')\n",
    "        plt.ylabel('% Correct')\n",
    "\n",
    "        # Add a legend\n",
    "        plt.legend()\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class: Vectorizer\n",
    "\n",
    "Objects of this class are vectorizers, like Bag-of-Words or Doc2Vec. They have very few attributes and methods.\n",
    "All of the attributes and methods will be overwritten by each object of this class.\n",
    "\n",
    "**Attributes:**\n",
    "\n",
    "| Name           | Type | Description                                                                                         |\n",
    "|----------------|------|-----------------------------------------------------------------------------------------------------|\n",
    "| vectorizerName | str | The name of this vectorizer. <br/> This will be the key for any dictionaries containing it.         |\n",
    "| description    | str | A breif discription of what this vectorizer is/does. <br/>Put the parameters here if there are any. |\n",
    "| model | Other | The actual model. Typically an object of a class like Gensim or SCM\n",
    "\n",
    "**Methods:**\n",
    "\n",
    "| Name                               | Description                                                                                          |\n",
    "|------------------------------------|------------------------------------------------------------------------------------------------------|\n",
    "| train(X_train: Series)             | Uses the training data to train the model.                                                           |\n",
    "| embed(titles: Series) -> DataFrame | Takes a list/dataFrame of titles and returns a DataFrame of the embeddings for each of them. |\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Vectorizer:\n",
    "    \"\"\"This class is to hold all of the Title Vectorizers, like Bag-of-Words and Doc2Vec. Each vectorizer is a specific object. The class methods all have the same input/output.\"\"\"\n",
    "\n",
    "    def __init__(self, vectorizerName):\n",
    "        self.vectorizerName = vectorizerName\n",
    "        self.description = \"Description goes here\"\n",
    "\n",
    "    def train(self, X_train):\n",
    "        \"\"\"Inputs the training data. Creates the self.model\"\"\"\n",
    "\n",
    "        self.model = self._train(X_train)\n",
    "\n",
    "    def _train(self, X_train):\n",
    "        \"\"\"Just a place holder for the actual function\"\"\"\n",
    "        pass\n",
    "\n",
    "    def embed(self, titles):\n",
    "        \"\"\"Given a data frame or series with only titles, will return a df of all of the features, indexed by id. The actual function will be added to each object.\"\"\"\n",
    "\n",
    "        df =  self._embed(titles, self.model)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def _embed(self, titles, model):\n",
    "        \"\"\"Just a place holder for the actual function.\"\"\"\n",
    "        pass\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Class: Classifier\n",
    "\n",
    "This class holds the classifiers, like XGBoost and Support Vector Machines.\n",
    "It also has very few attributes and methods.\n",
    "\n",
    "**Attributes:**\n",
    "\n",
    "|Name | Type | Description |\n",
    "|-----|-------|--------|\n",
    "| classifierName | str | The name of this classifier |\n",
    "| description | str | A brief description of this classifier |\n",
    "| model | Other | Where the actual model is stored. Typically a member of a totally different class. |\n",
    "\n",
    "**Methods:**\n",
    "\n",
    "|Name | Description|\n",
    "|-----| --------|\n",
    "|train(X_train: pd.Series, Y_train: np.array) | Trains the model |\n",
    "|predict(titles: pd.Series) | predicts where each title should go |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    \"\"\"This is the class the holds the classifiers\"\"\"\n",
    "\n",
    "    def __init__(self, classifierName):\n",
    "        self.classifierName = classifierName\n",
    "\n",
    "    def train(self, X_train, Y_train):\n",
    "        \"\"\"Input the X and Y training data. Then update the model\"\"\"\n",
    "\n",
    "        self.model = self._train(X_train, Y_train)\n",
    "\n",
    "    def _train(self, X_train, Y_train):\n",
    "        \"\"\"Where the real function is stored\"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict(self, title_vectors):\n",
    "        \"\"\"\n",
    "        :param title_vectors: A pandas dataframe of the vectorized titles\n",
    "        :return: A pandas series with the predictions\n",
    "        \"\"\"\n",
    "\n",
    "        return self._predict(title_vectors, self.model)\n",
    "\n",
    "    def _predict(self, titles, model):\n",
    "        \"\"\"where the actual function is stored\"\"\"\n",
    "        pass\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
